Example Data:
Assume our original dataset (data) has:

Application_Type: [1, 1, 2, 2]
Signal_Strength: [50, 55, 60, 65]
Latency: [20, 25, 30, 35]
Required_Bandwidth: [100, 120, 150, 170]
Allocated_Bandwidth: [90, 110, 140, 160]
User_ID: [1, 2, 3, 4]
Target Size
We want our augmented dataset to have target_size = 8.

Sampling Loop Explained:
Separate and Sample Data:
For Application_Type 1:

python
Copy code
app_data = data[data['Application_Type'] == 1]
This filters the original data to include only rows where Application_Type is 1:

Copy code
Application_Type | Signal_Strength | Latency | Required_Bandwidth | Allocated_Bandwidth | User_ID
1                | 50              | 20      | 100                 | 90                  | 1
1                | 55              | 25      | 120                 | 110                 | 2
Sampling:

python
Copy code
sampled_data = app_data.sample(rows_per_application, replace=True).reset_index(drop=True)
Here, if rows_per_application is 4, the code samples 4 rows with replacement. Since replace=True, the same row might appear multiple times in the sampled data. Resetting the index ensures a clean new index:

sql
Copy code
Application_Type | Signal_Strength | Latency | Required_Bandwidth | Allocated_Bandwidth | User_ID
1                | 50              | 20      | 100                 | 90                  | New Index 0
1                | 55              | 25      | 120                 | 110                 | New Index 1
1                | 50              | 20      | 100                 | 90                  | New Index 2
1                | 55              | 25      | 120                 | 110                 | New Index 3
Concatenate:

python
Copy code
augmented_data = pd.concat([augmented_data, sampled_data], ignore_index=True)
After processing all application types, the augmented_data DataFrame accumulates all sampled rows. For instance, if Application_Type 2 is similarly processed, you would see concatenated data from both types.

Adding Noise:
Add Noise:
python
Copy code
noise = np.random.normal(1, 1, augmented_data[numerical_features].shape)
augmented_data[numerical_features] += noise
Suppose the augmented_data (for simplicity) has:
Copy code
Application_Type | Signal_Strength | Latency | Required_Bandwidth | Allocated_Bandwidth | User_ID
1                | 50              | 20      | 100                 | 90                  | 1
1                | 55              | 25      | 120                 | 110                 | 2
Adding noise (mean=1, std=1) might yield:
Copy code
Application_Type | Signal_Strength | Latency | Required_Bandwidth | Allocated_Bandwidth | User_ID
1                | 51.2            | 22.1    | 99.3                | 88.7                | 1
1                | 54.8            | 26.0    | 121.8               | 111.4               | 2
Resetting User_ID:
Reset User_ID:
python
Copy code
augmented_data['User_ID'] = range(1, len(augmented_data) + 1)
If augmented_data has 8 rows after sampling and adding noise, the User_ID column is reset to ensure unique identifiers:
python
Copy code
Application_Type | Signal_Strength | Latency | Required_Bandwidth | Allocated_Bandwidth | User_ID
1                | 51.2            | 22.1    | 99.3                | 88.7                | 1
1                | 54.8            | 26.0    | 121.8               | 111.4               | 2
...
Saving the Augmented Dataset:
Save to CSV:
python
Copy code
augmented_random.to_csv('../data/augmented_dataset.csv', index=False)